{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2545f148-9c3d-4e8d-bb02-14e346ab4bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining globals\n",
    "job_info_file_partial_path = 'plugin=job_table/metric=job_info_marconi100/a_0_filter123_singlenode.csv'\n",
    "total_power_file_partial_path = 'plugin=ipmi_pub/metric=total_power/a_0_filter123_singlenode.csv'\n",
    "column_dtypes = {'resv_name': object}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6497e665-3593-42e3-b83b-ddb2013d1d7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All rows have consistent start time, end time and runtime values.\n",
      "All rows have consistent start time, end time and runtime values.\n",
      "All rows have consistent start time, end time and runtime values.\n",
      "All rows have consistent start time, end time and runtime values.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_183659/3273200332.py:17: DtypeWarning: Columns (88) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path, dtype=column_dtypes)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All rows have consistent start time, end time and runtime values.\n",
      "All rows have consistent start time, end time and runtime values.\n",
      "All rows have consistent start time, end time and runtime values.\n",
      "All rows have consistent start time, end time and runtime values.\n",
      "All rows have consistent start time, end time and runtime values.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Specify the root directory where your HPC job log dataset is located\n",
    "root_directory = '../data'\n",
    "\n",
    "# Iterate through each month folder\n",
    "for month_folder in os.listdir(root_directory):\n",
    "    month_path = os.path.join(root_directory, month_folder)\n",
    "\n",
    "    if os.path.isdir(month_path):\n",
    "        # Construct the file path based on the pattern\n",
    "        file_path = os.path.join(month_path, job_info_file_partial_path)\n",
    "\n",
    "        if os.path.exists(file_path):\n",
    "            \n",
    "            df = pd.read_csv(file_path, dtype=column_dtypes)\n",
    "                        \n",
    "            # Filter rows where start_time + runtime is not equal to end_time\n",
    "            invalid_rows = df[~((pd.to_datetime(df['start_time']) + pd.to_timedelta(df['run_time'], unit='s')) == pd.to_datetime(df['end_time']))]\n",
    "\n",
    "            # Print the invalid rows\n",
    "            if not invalid_rows.empty:\n",
    "                print(f'Invalid rows in {month_folder}:')\n",
    "                print(invalid_rows)\n",
    "                print('\\n---\\n')\n",
    "            else:\n",
    "                print(\"All rows have consistent start time, end time and runtime values.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87148490-6ebd-442b-b75e-00aaaf5500ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty DataFrame to store the merged results\n",
    "merged_df = pd.DataFrame()\n",
    "\n",
    "# Iterate through each month folder\n",
    "\n",
    "month_path = os.path.join(root_directory, \"year_month=22-08\")\n",
    "\n",
    "# Check if the item is a directory\n",
    "if os.path.isdir(month_path):\n",
    "    job_info_file_path = os.path.join(month_path, job_info_file_partial_path)\n",
    "    total_power_file_path = os.path.join(month_path, total_power_file_partial_path)\n",
    "\n",
    "    if os.path.exists(job_info_file_path) and os.path.exists(total_power_file_path):\n",
    "        # Load the job info and total power CSV files into DataFrames\n",
    "        job_info_df = pd.read_csv(job_info_file_path, dtype=column_dtypes)\n",
    "        total_power_df = pd.read_csv(total_power_file_path)\n",
    "\n",
    "        # Merge the DataFrames based on the 'job_id' column\n",
    "        merged_df_month = pd.merge(job_info_df, total_power_df, on='job_id', how='inner')\n",
    "\n",
    "        # Append the merged results to the overall merged DataFrame\n",
    "        merged_df = pd.concat([merged_df, merged_df_month], ignore_index=True)\n",
    "\n",
    "# Display the merged DataFrame\n",
    "print(\"Merged DataFrame:\")\n",
    "print(merged_df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
